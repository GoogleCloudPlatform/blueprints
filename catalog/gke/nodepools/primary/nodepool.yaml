apiVersion: container.cnrm.cloud.google.com/v1beta1
kind: ContainerNodePool
metadata:
  annotations:
    cnrm.cloud.google.com/blueprint: cnrm/gke:gke-cluster-nodepool/v0.2.0-alpha.1
    cnrm.cloud.google.com/project-id: platform-project-id # {"$kpt-set":"platform-project-id"}
  name: example-us-east4-primary # {"$kpt-set":"krm-nodepool-name"}
  namespace: config-control # {"$kpt-set":"platform-namespace"}
spec:
  autoscaling:
    # maxNodeCount is per-zone, for regional clusters
    maxNodeCount: 2 # {"$kpt-set":"max-node-count"}
    # minNodeCount is per-zone, for regional clusters
    minNodeCount: 1
  clusterRef:
    name: example-us-east4 # {"$kpt-set":"cluster-name"}
  # At least one node is required for cluster system components.
  # initialNodeCount is per-zone, for regional clusters
  initialNodeCount: 1
  location: us-east4 # {"$kpt-set":"location"}
  # Enable auto repairs and upgrades by default.
  # Disable if you have workloads that cannot tollerate disruption.
  management:
    autoRepair: true
    autoUpgrade: true
  # Default reduced to better fit on e2-standard-16 machines.
  # 4 pods per vCPU, 8 pods per physical core, ~1 pod per GB of memory. 
  maxPodsPerNode: 64
  nodeConfig:
    # diskSizeGb should include enough space for system components and the
    # container image cache, in addition to space used by user workloads.
    diskSizeGb: 100
    # Default to SSD for higher IOPS / $ vs standard disks.
    diskType: pd-ssd
    labels:
      gke.io/nodepool: primary # {"$kpt-set":"nodepool-name"}
    # Default to e2, the most modern & efficient machine type family.
    machineType: e2-standard-16
    # Explicit scopes are required when using a custom serice account.
    oauthScopes:
    - storage-ro
    - https://www.googleapis.com/auth/logging.write
    - https://www.googleapis.com/auth/monitoring
    serviceAccountRef:
      name: gke-example-us-east4-primary # {"$kpt-set":"krm-service-account-name"}
